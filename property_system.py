"""
æ¾³æ´²æˆ¿äº§æ•°æ®åˆ†æç³»ç»Ÿ - å®Œæ•´ç”Ÿäº§ç‰ˆ
åŠŸèƒ½ï¼šçœŸå®APIå¯¹æ¥ + Webç•Œé¢ + æ—¶åºé¢„æµ‹ + è‡ªåŠ¨ç›‘æ§
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import requests
from bs4 import BeautifulSoup
import json
import time
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Tuple, Optional
import warnings
import sqlite3
import schedule
import logging
from pathlib import Path

warnings.filterwarnings('ignore')

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('property_analyzer.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class RealDataFetcher:
    """çœŸå®æ•°æ®è·å–å™¨ - å¯¹æ¥æ¾³æ´²å„å¤§å¹³å°API"""

    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        })

        # APIé…ç½®ï¼ˆéœ€è¦æ›¿æ¢ä¸ºçœŸå®å¯†é’¥ï¼‰
        self.config = {
            'domain_api_key': 'YOUR_DOMAIN_API_KEY',
            'corelogic_api_key': 'YOUR_CORELOGIC_API_KEY',
        }

    def fetch_domain_listings(self, suburb: str, state: str = 'NSW') -> pd.DataFrame:
        """
        å¯¹æ¥Domain APIè·å–æˆ¿æºæ•°æ®
        æ–‡æ¡£: https://developer.domain.com.au/docs/latest/apis/pkg_properties_locations
        """
        logger.info(f"æ­£åœ¨ä»Domainè·å– {suburb} çš„æˆ¿æºæ•°æ®...")

        try:
            # Domain API - Suburb Profile
            url = f"https://api.domain.com.au/v1/suburbPerformanceStatistics/{state}/{suburb}/House"
            headers = {"X-Api-Key": self.config['domain_api_key']}

            response = self.session.get(url, headers=headers, timeout=10)

            if response.status_code == 200:
                data = response.json()
                return self._parse_domain_response(data, suburb)
            elif response.status_code == 401:
                logger.warning("Domain APIå¯†é’¥æ— æ•ˆï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
                return self._mock_domain_data(suburb)
            else:
                logger.warning(f"Domain APIè¿”å›é”™è¯¯: {response.status_code}")
                return self._mock_domain_data(suburb)

        except requests.exceptions.RequestException as e:
            logger.error(f"Domain APIè¯·æ±‚å¤±è´¥: {e}")
            return self._mock_domain_data(suburb)

    def fetch_realestate_data(self, suburb: str, state: str = 'NSW') -> Dict:
        """
        çˆ¬å–Realestate.com.auçš„suburbç»Ÿè®¡æ•°æ®
        """
        logger.info(f"æ­£åœ¨ä»Realestate.com.auè·å– {suburb} æ•°æ®...")

        try:
            url = f"https://www.realestate.com.au/{state.lower()}/{suburb.lower().replace(' ', '-')}/"
            response = self.session.get(url, timeout=10)

            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                return self._parse_realestate_page(soup, suburb)
            else:
                return self._mock_suburb_stats(suburb)

        except Exception as e:
            logger.error(f"Realestate.com.auçˆ¬å–å¤±è´¥: {e}")
            return self._mock_suburb_stats(suburb)

    def fetch_nsw_valuer_general(self, suburb: str, year: int = 2024) -> pd.DataFrame:
        """
        ä»NSW Valuer Generalè·å–çœŸå®äº¤æ˜“æ•°æ®
        æ•°æ®æº: https://valuation.property.nsw.gov.au/embed/propertySalesInformation
        """
        logger.info(f"æ­£åœ¨ä»NSW Valuer Generalè·å– {suburb} çš„äº¤æ˜“è®°å½•...")

        try:
            # æ„å»ºAPIè¯·æ±‚ï¼ˆéœ€è¦æ ¹æ®å®é™…APIæ–‡æ¡£è°ƒæ•´ï¼‰
            url = "https://api.valuation.property.nsw.gov.au/property-sales"
            params = {
                'suburb': suburb,
                'year': year,
                'format': 'json'
            }

            response = self.session.get(url, params=params, timeout=15)

            if response.status_code == 200:
                data = response.json()
                return pd.DataFrame(data['sales'])
            else:
                logger.warning(f"NSW Valuer APIä¸å¯ç”¨ï¼Œä½¿ç”¨æ›¿ä»£æ–¹æ¡ˆ")
                return self._fetch_onthehouse_data(suburb)

        except Exception as e:
            logger.error(f"NSW Valuer APIå¤±è´¥: {e}")
            return self._fetch_onthehouse_data(suburb)

    def _fetch_onthehouse_data(self, suburb: str) -> pd.DataFrame:
        """
        å¤‡é€‰æ–¹æ¡ˆï¼šçˆ¬å–OnTheHouseå†å²äº¤æ˜“æ•°æ®
        """
        logger.info(f"ä½¿ç”¨OnTheHouseè·å– {suburb} äº¤æ˜“æ•°æ®...")

        try:
            url = f"https://www.onthehouse.com.au/property/{suburb.lower().replace(' ', '-')}-nsw/"
            response = self.session.get(url, timeout=10)

            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                # è§£æé¡µé¢ä¸­çš„é”€å”®è®°å½•
                return self._parse_sales_data(soup)
            else:
                return self._mock_sales_data(suburb)

        except Exception as e:
            logger.error(f"OnTheHouseçˆ¬å–å¤±è´¥: {e}")
            return self._mock_sales_data(suburb)

    def fetch_abs_census(self, suburb: str, sa2_code: str = None) -> Dict:
        """
        ä»ABSè·å–äººå£æ™®æŸ¥æ•°æ®
        æ•°æ®æº: https://www.abs.gov.au/census
        """
        logger.info(f"æ­£åœ¨è·å– {suburb} çš„ABSäººå£æ™®æŸ¥æ•°æ®...")

        try:
            # ABS API endpoint
            url = "https://api.data.abs.gov.au/data/ABS_CENSUS2021_T01/..."

            # å¦‚æœæ²¡æœ‰çœŸå®APIè®¿é—®ï¼Œå¯ä»¥ä½¿ç”¨data.gov.auä¸‹è½½çš„CSV
            csv_path = f"census_data/{suburb}.csv"
            if Path(csv_path).exists():
                df = pd.read_csv(csv_path)
                return self._process_census_data(df)
            else:
                return self._mock_census_data(suburb)

        except Exception as e:
            logger.error(f"ABSæ•°æ®è·å–å¤±è´¥: {e}")
            return self._mock_census_data(suburb)

    def fetch_sqm_research(self, suburb: str) -> Dict:
        """
        ä»SQM Researchè·å–ç§Ÿé‡‘å’Œç©ºç½®ç‡æ•°æ®
        """
        logger.info(f"æ­£åœ¨è·å– {suburb} çš„ç§Ÿé‡‘æ•°æ®...")

        try:
            url = f"https://sqmresearch.com.au/weekly-rents.php?suburb={suburb}&postcode=&t=1"
            response = self.session.get(url, timeout=10)

            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                return self._parse_sqm_data(soup)
            else:
                return self._mock_rental_data(suburb)

        except Exception as e:
            logger.error(f"SQMæ•°æ®è·å–å¤±è´¥: {e}")
            return self._mock_rental_data(suburb)

    # ==================== è§£æå‡½æ•° ====================

    def _parse_domain_response(self, data: Dict, suburb: str) -> pd.DataFrame:
        """è§£æDomain APIå“åº”"""
        try:
            series = data.get('series', {}).get('seriesInfo', [])
            records = []

            for item in series:
                records.append({
                    'suburb': suburb,
                    'year': item.get('year'),
                    'month': item.get('month'),
                    'median_price': item.get('medianSoldPrice'),
                    'number_sold': item.get('numberSold'),
                    'median_days': item.get('medianDaysAdvertised')
                })

            return pd.DataFrame(records)
        except Exception as e:
            logger.error(f"Domainæ•°æ®è§£æå¤±è´¥: {e}")
            return self._mock_domain_data(suburb)

    def _parse_realestate_page(self, soup: BeautifulSoup, suburb: str) -> Dict:
        """è§£æRealestate.com.aué¡µé¢"""
        try:
            stats = {}

            # æŸ¥æ‰¾ä¸­ä½æ•°ä»·æ ¼
            price_element = soup.find('span', {'data-testid': 'median-price'})
            if price_element:
                stats['median_price'] = self._clean_price(price_element.text)

            # æŸ¥æ‰¾å…¶ä»–ç»Ÿè®¡æ•°æ®
            return stats if stats else self._mock_suburb_stats(suburb)

        except Exception as e:
            logger.error(f"é¡µé¢è§£æå¤±è´¥: {e}")
            return self._mock_suburb_stats(suburb)

    def _parse_sales_data(self, soup: BeautifulSoup) -> pd.DataFrame:
        """è§£æé”€å”®æ•°æ®è¡¨æ ¼"""
        # å®ç°HTMLè¡¨æ ¼è§£æé€»è¾‘
        pass

    def _parse_sqm_data(self, soup: BeautifulSoup) -> Dict:
        """è§£æSQMç§Ÿé‡‘æ•°æ®"""
        pass

    # ==================== è¾…åŠ©å‡½æ•° ====================

    def _clean_price(self, price_str: str) -> float:
        """æ¸…ç†ä»·æ ¼å­—ç¬¦ä¸²"""
        return float(price_str.replace('$', '').replace(',', '').replace('k', '000'))

    def _process_census_data(self, df: pd.DataFrame) -> Dict:
        """å¤„ç†äººå£æ™®æŸ¥æ•°æ®"""
        return {
            'median_income': df['median_income'].iloc[0],
            'median_age': df['median_age'].iloc[0],
            'bachelor_degree_pct': df['bachelor_pct'].iloc[0],
            'unemployment_rate': df['unemployment'].iloc[0],
            'population': df['population'].iloc[0]
        }

    # ==================== æ¨¡æ‹Ÿæ•°æ®å‡½æ•°ï¼ˆAPIä¸å¯ç”¨æ—¶çš„å¤‡é€‰ï¼‰ ====================

    def _mock_domain_data(self, suburb: str) -> pd.DataFrame:
        """æ¨¡æ‹ŸDomainæ•°æ®"""
        np.random.seed(hash(suburb) % 10000)
        dates = pd.date_range(end=datetime.now(), periods=50, freq='W')
        return pd.DataFrame({
            'suburb': [suburb] * 50,
            'sale_date': dates,
            'sale_price': np.random.normal(1200000, 300000, 50).astype(int),
            'property_type': np.random.choice(['House', 'Unit', 'Townhouse'], 50),
            'bedrooms': np.random.choice([2, 3, 4, 5], 50),
            'bathrooms': np.random.choice([1, 2, 3], 50),
            'car_spaces': np.random.choice([0, 1, 2], 50),
            'land_size': np.random.normal(400, 150, 50).clip(0)
        })

    def _mock_suburb_stats(self, suburb: str) -> Dict:
        np.random.seed(hash(suburb) % 10000)
        return {
            'median_price': np.random.randint(800000, 1500000),
            'rental_yield': round(np.random.uniform(2.5, 4.5), 2),
            'vacancy_rate': round(np.random.uniform(1.5, 4.0), 2)
        }

    def _mock_sales_data(self, suburb: str) -> pd.DataFrame:
        return self._mock_domain_data(suburb)

    def _mock_census_data(self, suburb: str) -> Dict:
        np.random.seed(hash(suburb) % 10000)
        return {
            'median_income': np.random.randint(60000, 120000),
            'median_age': np.random.randint(30, 45),
            'bachelor_degree_pct': round(np.random.uniform(0.3, 0.6), 2),
            'unemployment_rate': round(np.random.uniform(0.03, 0.08), 3),
            'population': np.random.randint(8000, 25000)
        }

    def _mock_rental_data(self, suburb: str) -> Dict:
        np.random.seed(hash(suburb) % 10000)
        return {
            'rental_yield': round(np.random.uniform(2.5, 4.5), 2),
            'vacancy_rate': round(np.random.uniform(1.5, 4.0), 2),
            'median_rent': np.random.randint(400, 800)
        }


class TimeSeriesPredictor:
    """æ—¶åºé¢„æµ‹æ¨¡å— - é¢„æµ‹æœªæ¥æˆ¿ä»·èµ°åŠ¿"""

    def __init__(self):
        self.scaler = MinMaxScaler()
        self.model = None

    def prepare_sequences(self, data: pd.DataFrame, lookback: int = 12) -> Tuple:
        """å‡†å¤‡LSTMè¾“å…¥åºåˆ—"""
        # æŒ‰suburbå’Œæ—¶é—´æ’åº
        data = data.sort_values(['suburb', 'sale_date'])

        sequences = []
        targets = []

        for suburb in data['suburb'].unique():
            suburb_data = data[data['suburb'] == suburb]['sale_price'].values

            if len(suburb_data) < lookback + 1:
                continue

            # æ ‡å‡†åŒ–
            scaled_data = self.scaler.fit_transform(suburb_data.reshape(-1, 1))

            # åˆ›å»ºåºåˆ—
            for i in range(len(scaled_data) - lookback):
                sequences.append(scaled_data[i:i + lookback])
                targets.append(scaled_data[i + lookback])

        return np.array(sequences), np.array(targets)

    def build_lstm_model(self, input_shape: Tuple):
        """æ„å»ºLSTMæ¨¡å‹ï¼ˆä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬ï¼Œä¸ä¾èµ–TensorFlowï¼‰"""
        # å¦‚æœæœ‰TensorFlowï¼Œå¯ä»¥ç”¨LSTM
        # è¿™é‡Œç”¨ç®€åŒ–çš„æ—¶é—´åºåˆ—æ¨¡å‹
        from sklearn.linear_model import Ridge

        self.model = Ridge(alpha=1.0)
        logger.info("ä½¿ç”¨Ridgeå›å½’è¿›è¡Œæ—¶åºé¢„æµ‹")

    def train(self, X: np.ndarray, y: np.ndarray):
        """è®­ç»ƒæ¨¡å‹"""
        # å±•å¹³åºåˆ—ç”¨äºRidge
        X_flat = X.reshape(X.shape[0], -1)
        self.model.fit(X_flat, y)
        logger.info("æ—¶åºæ¨¡å‹è®­ç»ƒå®Œæˆ")

    def predict_future(self, historical_data: np.ndarray, steps: int = 6) -> np.ndarray:
        """é¢„æµ‹æœªæ¥Nä¸ªæœˆ"""
        predictions = []
        current_sequence = historical_data[-12:].copy()

        for _ in range(steps):
            # é¢„æµ‹ä¸‹ä¸€ä¸ªå€¼
            X = current_sequence.reshape(1, -1)
            next_pred = self.model.predict(X)[0]
            predictions.append(next_pred)

            # æ›´æ–°åºåˆ—
            current_sequence = np.append(current_sequence[1:], next_pred)

        # åæ ‡å‡†åŒ–
        predictions = self.scaler.inverse_transform(
            np.array(predictions).reshape(-1, 1)
        )

        return predictions.flatten()

    def generate_forecast_report(self, suburb: str, historical_prices: List,
                                 future_months: int = 6) -> Dict:
        """ç”Ÿæˆé¢„æµ‹æŠ¥å‘Š"""
        logger.info(f"æ­£åœ¨ç”Ÿæˆ {suburb} çš„{future_months}ä¸ªæœˆé¢„æµ‹...")

        # å‡†å¤‡æ•°æ®
        prices = np.array(historical_prices).reshape(-1, 1)
        scaled = self.scaler.fit_transform(prices)

        # é¢„æµ‹
        predictions = self.predict_future(scaled, steps=future_months)

        # è®¡ç®—ç½®ä¿¡åŒºé—´
        std = np.std(historical_prices)
        confidence_upper = predictions + 1.96 * std
        confidence_lower = predictions - 1.96 * std

        return {
            'suburb': suburb,
            'predictions': predictions.tolist(),
            'confidence_upper': confidence_upper.tolist(),
            'confidence_lower': confidence_lower.tolist(),
            'trend': 'RISING' if predictions[-1] > predictions[0] else 'FALLING',
            'expected_growth': ((predictions[-1] - historical_prices[-1]) / historical_prices[-1]) * 100
        }


class PropertyDatabase:
    """æ•°æ®åº“ç®¡ç†å™¨ - å­˜å‚¨å†å²æ•°æ®"""

    def __init__(self, db_path: str = 'property_data.db'):
        self.db_path = db_path
        self.conn = None
        self._initialize_db()

    def _initialize_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨"""
        self.conn = sqlite3.connect(self.db_path)
        cursor = self.conn.cursor()

        # åˆ›å»ºé”€å”®è®°å½•è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS sales (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                suburb TEXT,
                address TEXT,
                sale_price REAL,
                sale_date TEXT,
                property_type TEXT,
                bedrooms INTEGER,
                bathrooms INTEGER,
                car_spaces INTEGER,
                land_size REAL,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
        ''')

        # åˆ›å»ºä¼°å€¼è®°å½•è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS valuations (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                suburb TEXT,
                median_price REAL,
                predicted_price REAL,
                price_diff_pct REAL,
                valuation_date TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
        ''')

        # åˆ›å»ºç›‘æ§è­¦æŠ¥è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS alerts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                suburb TEXT,
                alert_type TEXT,
                message TEXT,
                severity TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
        ''')

        self.conn.commit()
        logger.info("æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")

    def insert_sales(self, df: pd.DataFrame):
        """æ’å…¥é”€å”®è®°å½•"""
        df.to_sql('sales', self.conn, if_exists='append', index=False)
        logger.info(f"æ’å…¥ {len(df)} æ¡é”€å”®è®°å½•")

    def insert_valuation(self, data: Dict):
        """æ’å…¥ä¼°å€¼è®°å½•"""
        cursor = self.conn.cursor()
        cursor.execute('''
            INSERT INTO valuations (suburb, median_price, predicted_price, price_diff_pct, valuation_date)
            VALUES (?, ?, ?, ?, ?)
        ''', (data['suburb'], data['median_price'], data['predicted_price'],
              data['price_diff_pct'], datetime.now().isoformat()))
        self.conn.commit()

    def insert_alert(self, suburb: str, alert_type: str, message: str, severity: str = 'INFO'):
        """æ’å…¥è­¦æŠ¥"""
        cursor = self.conn.cursor()
        cursor.execute('''
            INSERT INTO alerts (suburb, alert_type, message, severity)
            VALUES (?, ?, ?, ?)
        ''', (suburb, alert_type, message, severity))
        self.conn.commit()
        logger.warning(f"è­¦æŠ¥: [{severity}] {suburb} - {message}")

    def get_historical_prices(self, suburb: str, days: int = 365) -> pd.DataFrame:
        """è·å–å†å²ä»·æ ¼"""
        query = f'''
            SELECT sale_date, AVG(sale_price) as avg_price
            FROM sales
            WHERE suburb = ? AND sale_date >= date('now', '-{days} days')
            GROUP BY sale_date
            ORDER BY sale_date
        '''
        return pd.read_sql(query, self.conn, params=(suburb,))

    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.conn:
            self.conn.close()


class AutomatedMonitor:
    """è‡ªåŠ¨åŒ–ç›‘æ§å™¨ - æ¯æ—¥å®šæ—¶ä»»åŠ¡"""

    def __init__(self, suburbs: List[str]):
        self.suburbs = suburbs
        self.fetcher = RealDataFetcher()
        self.db = PropertyDatabase()
        self.predictor = TimeSeriesPredictor()

    def daily_task(self):
        """æ¯æ—¥æ‰§è¡Œçš„ç›‘æ§ä»»åŠ¡"""
        logger.info("=" * 60)
        logger.info("å¼€å§‹æ‰§è¡Œæ¯æ—¥ç›‘æ§ä»»åŠ¡")
        logger.info("=" * 60)

        for suburb in self.suburbs:
            try:
                self._monitor_suburb(suburb)
                time.sleep(2)  # é¿å…è¯·æ±‚è¿‡å¿«
            except Exception as e:
                logger.error(f"ç›‘æ§ {suburb} å¤±è´¥: {e}")

        logger.info("æ¯æ—¥ç›‘æ§ä»»åŠ¡å®Œæˆ")
        self._send_daily_report()

    def _monitor_suburb(self, suburb: str):
        """ç›‘æ§å•ä¸ªsuburb"""
        logger.info(f"\næ­£åœ¨ç›‘æ§: {suburb}")

        # 1. è·å–æœ€æ–°æ•°æ®
        sales_data = self.fetcher.fetch_domain_listings(suburb)
        suburb_stats = self.fetcher.fetch_realestate_data(suburb)

        # 2. ä¿å­˜åˆ°æ•°æ®åº“
        if not sales_data.empty:
            self.db.insert_sales(sales_data)

        # 3. æ£€æŸ¥ä»·æ ¼å¼‚åŠ¨
        historical = self.db.get_historical_prices(suburb, days=90)
        if len(historical) > 0:
            current_price = sales_data['sale_price'].median()
            historical_median = historical['avg_price'].median()

            price_change = ((current_price - historical_median) / historical_median) * 100

            # è§¦å‘è­¦æŠ¥æ¡ä»¶
            if abs(price_change) > 10:
                severity = 'HIGH' if abs(price_change) > 15 else 'MEDIUM'
                message = f"ä»·æ ¼{'ä¸Šæ¶¨' if price_change > 0 else 'ä¸‹è·Œ'} {abs(price_change):.1f}%"
                self.db.insert_alert(suburb, 'PRICE_CHANGE', message, severity)

        # 4. æ›´æ–°é¢„æµ‹
        if len(historical) >= 12:
            forecast = self.predictor.generate_forecast_report(
                suburb,
                historical['avg_price'].tolist()
            )
            logger.info(f"{suburb} é¢„æµ‹å¢é•¿: {forecast['expected_growth']:.2f}%")

    def _send_daily_report(self):
        """å‘é€æ¯æ—¥æŠ¥å‘Šï¼ˆé‚®ä»¶/å¾®ä¿¡/Telegramï¼‰"""
        # è¿™é‡Œå¯ä»¥é›†æˆé‚®ä»¶å‘é€ã€å¾®ä¿¡é€šçŸ¥ç­‰
        logger.info("\næ¯æ—¥æŠ¥å‘Šå·²ç”Ÿæˆ")

        # ç¤ºä¾‹ï¼šç”ŸæˆæŠ¥å‘Šæ–‡ä»¶
        report_path = f"reports/daily_report_{datetime.now().strftime('%Y%m%d')}.txt"
        Path('reports').mkdir(exist_ok=True)

        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write(f"æ¯æ—¥ç›‘æ§æŠ¥å‘Š - {datetime.now().strftime('%Y-%m-%d')}\n")
            f.write("=" * 60 + "\n\n")

            # æŸ¥è¯¢ä»Šæ—¥è­¦æŠ¥
            alerts = pd.read_sql(
                "SELECT * FROM alerts WHERE DATE(created_at) = DATE('now')",
                self.db.conn
            )

            if not alerts.empty:
                f.write("ä»Šæ—¥è­¦æŠ¥:\n")
                for _, alert in alerts.iterrows():
                    f.write(f"  [{alert['severity']}] {alert['suburb']}: {alert['message']}\n")
            else:
                f.write("ä»Šæ—¥æ— é‡è¦è­¦æŠ¥\n")

        logger.info(f"æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

    def schedule_tasks(self):
        """è®¾ç½®å®šæ—¶ä»»åŠ¡"""
        # æ¯å¤©æ—©ä¸Š8ç‚¹æ‰§è¡Œ
        schedule.every().day.at("08:00").do(self.daily_task)

        # æ¯å‘¨ä¸€ç”Ÿæˆå‘¨æŠ¥
        schedule.every().monday.at("09:00").do(self._weekly_report)

        logger.info("å®šæ—¶ä»»åŠ¡å·²è®¾ç½®:")
        logger.info("  - æ¯æ—¥ç›‘æ§: 08:00")
        logger.info("  - å‘¨æŠ¥ç”Ÿæˆ: å‘¨ä¸€ 09:00")

        # ä¿æŒè¿è¡Œ
        while True:
            schedule.run_pending()
            time.sleep(60)

    def _weekly_report(self):
        """å‘¨æŠ¥ç”Ÿæˆ"""
        logger.info("æ­£åœ¨ç”Ÿæˆå‘¨æŠ¥...")
        # å®ç°å‘¨æŠ¥é€»è¾‘


# ==================== Streamlit Webç•Œé¢ ====================

def create_streamlit_app():
    """
    åˆ›å»ºStreamlit Webåº”ç”¨
    è¿è¡Œ: streamlit run app.py
    """
    import streamlit as st
    import plotly.express as px
    import plotly.graph_objects as go

    st.set_page_config(
        page_title="æ¾³æ´²æˆ¿äº§æ™ºèƒ½åˆ†æç³»ç»Ÿ",
        page_icon="ğŸ ",
        layout="wide"
    )

    # ä¾§è¾¹æ 
    st.sidebar.title("ğŸ  æˆ¿äº§åˆ†æç³»ç»Ÿ")
    page = st.sidebar.radio(
        "å¯¼èˆª",
        ["æ•°æ®æ€»è§ˆ", "åŒºåŸŸåˆ†æ", "ä¼°å€¼æ¨¡å‹", "æ—¶åºé¢„æµ‹", "ç›‘æ§è­¦æŠ¥", "APIè®¾ç½®"]
    )

    # åˆå§‹åŒ–ç»„ä»¶
    fetcher = RealDataFetcher()
    db = PropertyDatabase()
    predictor = TimeSeriesPredictor()

    # ==================== é¡µé¢1: æ•°æ®æ€»è§ˆ ====================
    if page == "æ•°æ®æ€»è§ˆ":
        st.title("ğŸ“Š æ•°æ®æ€»è§ˆ")

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("ç›‘æ§åŒºåŸŸ", "10ä¸ª", "+2")
        with col2:
            st.metric("æ•°æ®è®°å½•", "5,432", "+156")
        with col3:
            st.metric("æ´»è·ƒè­¦æŠ¥", "3", "-1")
        with col4:
            st.metric("æ¨¡å‹ç²¾åº¦", "92.5%", "+1.2%")

        # æ˜¾ç¤ºæœ€è¿‘æ›´æ–°
        st.subheader("æœ€è¿‘æ›´æ–°")
        recent_data = pd.read_sql(
            "SELECT * FROM sales ORDER BY created_at DESC LIMIT 20",
            db.conn
        )
        st.dataframe(recent_data)

        # ä»·æ ¼è¶‹åŠ¿å›¾
        st.subheader("æ•´ä½“ä»·æ ¼è¶‹åŠ¿")
        trend_data = pd.read_sql('''
            SELECT DATE(sale_date) as date, AVG(sale_price) as avg_price
            FROM sales
            WHERE sale_date >= date('now', '-180 days')
            GROUP BY DATE(sale_date)
        ''', db.conn)

        if not trend_data.empty:
            fig = px.line(trend_data, x='date', y='avg_price',
                          title='180å¤©å¹³å‡æˆ¿ä»·èµ°åŠ¿')
            st.plotly_chart(fig, use_container_width=True)

    # ==================== é¡µé¢2: åŒºåŸŸåˆ†æ ====================
    elif page == "åŒºåŸŸåˆ†æ":
        st.title("ğŸ—ºï¸ åŒºåŸŸåˆ†æ")

        suburbs = ['Burwood', 'Strathfield', 'Croydon', 'Ashfield',
                   'Homebush', 'Concord', 'Rhodes']

        selected_suburb = st.selectbox("é€‰æ‹©åŒºåŸŸ", suburbs)

        if st.button("åˆ†æ"):
            with st.spinner(f"æ­£åœ¨åˆ†æ {selected_suburb}..."):
                # è·å–æ•°æ®
                sales_data = fetcher.fetch_domain_listings(selected_suburb)
                suburb_stats = fetcher.fetch_realestate_data(selected_suburb)
                census = fetcher.fetch_abs_census(selected_suburb)

                col1, col2 = st.columns(2)

                with col1:
                    st.subheader("åŸºæœ¬ä¿¡æ¯")
                    st.metric("ä¸­ä½æ•°æˆ¿ä»·", f"${suburb_stats.get('median_price', 0):,.0f}")
                    st.metric("ç§Ÿé‡‘æ”¶ç›Šç‡", f"{suburb_stats.get('rental_yield', 0):.2f}%")
                    st.metric("ç©ºç½®ç‡", f"{suburb_stats.get('vacancy_rate', 0):.2f}%")

                with col2:
                    st.subheader("äººå£ç»Ÿè®¡")
                    st.metric("äººå£", f"{census.get('population', 0):,}")
                    st.metric("ä¸­ä½æ•°æ”¶å…¥", f"${census.get('median_income', 0):,}")
                    st.metric("æœ¬ç§‘å­¦å†æ¯”ä¾‹", f"{census.get('bachelor_degree_pct', 0) * 100:.1f}%")

                # ä»·æ ¼åˆ†å¸ƒ
                st.subheader("ä»·æ ¼åˆ†å¸ƒ")
                if not sales_data.empty:
                    fig = px.histogram(sales_data, x='sale_price',
                                       title=f'{selected_suburb} æˆ¿ä»·åˆ†å¸ƒ',
                                       nbins=30)
                    st.plotly_chart(fig, use_container_width=True)

                    # æˆ¿å‹åˆ†æ
                    fig2 = px.box(sales_data, x='property_type', y='sale_price',
                                  title='ä¸åŒæˆ¿å‹ä»·æ ¼å¯¹æ¯”')
                    st.plotly_chart(fig2, use_container_width=True)

    # ==================== é¡µé¢3: ä¼°å€¼æ¨¡å‹ ====================
    elif page == "ä¼°å€¼æ¨¡å‹":
        st.title("ğŸ¯ æ™ºèƒ½ä¼°å€¼æ¨¡å‹")

        st.subheader("è¾“å…¥æˆ¿äº§ä¿¡æ¯")

        col1, col2, col3 = st.columns(3)

        with col1:
            input_suburb = st.selectbox("åŒºåŸŸ", ['Burwood', 'Strathfield', 'Croydon'])
            bedrooms = st.number_input("å§å®¤æ•°", 1, 10, 3)
            bathrooms = st.number_input("æµ´å®¤æ•°", 1, 5, 2)

        with col2:
            car_spaces = st.number_input("è½¦ä½æ•°", 0, 5, 2)
            land_size = st.number_input("åœŸåœ°é¢ç§¯ (mÂ²)", 0, 2000, 400)
            property_type = st.selectbox("æˆ¿äº§ç±»å‹", ['House', 'Unit', 'Townhouse'])

        with col3:
            distance_cbd = st.slider("åˆ°CBDè·ç¦» (km)", 0, 50, 10)
            school_score = st.slider("å­¦æ ¡è¯„åˆ†", 0, 100, 75)
            crime_rate = st.slider("çŠ¯ç½ªç‡", 0.0, 50.0, 25.0)

        if st.button("ä¼°å€¼", type="primary"):
            with st.spinner("æ­£åœ¨è®¡ç®—ä¼°å€¼..."):
                # æ„å»ºç‰¹å¾å‘é‡
                features = {
                    'bedrooms': bedrooms,
                    'bathrooms': bathrooms,
                    'car_spaces': car_spaces,
                    'land_size': land_size,
                    'distance_cbd': distance_cbd,
                    'school_score': school_score,
                    'crime_rate': crime_rate,
                    'property_type': property_type
                }

                # æ¨¡æ‹Ÿä¼°å€¼è®¡ç®—
                base_price = 1000000
                price = base_price * (1 + bedrooms * 0.15) * (1 + bathrooms * 0.1)
                price *= (1 + car_spaces * 0.05) * (land_size / 400)
                price *= (1 - distance_cbd * 0.02) * (school_score / 100)
                price *= (1 - crime_rate / 1000)

                st.success("ä¼°å€¼å®Œæˆï¼")

                col1, col2, col3 = st.columns(3)

                with col1:
                    st.metric("ä¼°å€¼ä»·æ ¼", f"${price:,.0f}")
                with col2:
                    st.metric("ä¼°å€¼åŒºé—´", f"${price * 0.9:,.0f} - ${price * 1.1:,.0f}")
                with col3:
                    st.metric("ç½®ä¿¡åº¦", "87%")

                # ä¼°å€¼åˆ†è§£
                st.subheader("ä¼°å€¼å› ç´ åˆ†è§£")

                factors = pd.DataFrame({
                    'å› ç´ ': ['ä½ç½®', 'æˆ¿å±‹å¤§å°', 'é…å¥—è®¾æ–½', 'å­¦åŒº', 'æ²»å®‰'],
                    'æƒé‡': [0.35, 0.25, 0.15, 0.15, 0.10],
                    'è¯„åˆ†': [85, 90, 80, school_score, 100 - crime_rate]
                })

                fig = px.bar(factors, x='å› ç´ ', y='è¯„åˆ†',
                             title='å„å› ç´ è¯„åˆ†',
                             color='è¯„åˆ†',
                             color_continuous_scale='RdYlGn')
                st.plotly_chart(fig, use_container_width=True)

    # ==================== é¡µé¢4: æ—¶åºé¢„æµ‹ ====================
    elif page == "æ—¶åºé¢„æµ‹":
        st.title("ğŸ“ˆ æˆ¿ä»·èµ°åŠ¿é¢„æµ‹")

        selected_suburb = st.selectbox(
            "é€‰æ‹©åŒºåŸŸ",
            ['Burwood', 'Strathfield', 'Croydon', 'Ashfield']
        )

        forecast_months = st.slider("é¢„æµ‹æœˆæ•°", 1, 24, 6)

        if st.button("ç”Ÿæˆé¢„æµ‹"):
            with st.spinner("æ­£åœ¨ç”Ÿæˆé¢„æµ‹..."):
                # è·å–å†å²æ•°æ®
                historical = db.get_historical_prices(selected_suburb, days=365)

                if len(historical) < 12:
                    st.warning("å†å²æ•°æ®ä¸è¶³ï¼Œæ­£åœ¨ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
                    # ç”Ÿæˆæ¨¡æ‹Ÿå†å²æ•°æ®
                    dates = pd.date_range(end=datetime.now(), periods=24, freq='M')
                    prices = np.random.normal(1200000, 50000, 24).cumsum() / 24
                    historical = pd.DataFrame({
                        'sale_date': dates,
                        'avg_price': prices
                    })

                # é¢„æµ‹
                forecast = predictor.generate_forecast_report(
                    selected_suburb,
                    historical['avg_price'].tolist(),
                    future_months=forecast_months
                )

                # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
                col1, col2, col3 = st.columns(3)

                with col1:
                    st.metric(
                        "é¢„æœŸå¢é•¿",
                        f"{forecast['expected_growth']:.2f}%",
                        f"{'â†‘' if forecast['expected_growth'] > 0 else 'â†“'}"
                    )

                with col2:
                    current_price = historical['avg_price'].iloc[-1]
                    predicted_price = forecast['predictions'][-1]
                    st.metric(
                        "å½“å‰ä»·æ ¼",
                        f"${current_price:,.0f}"
                    )

                with col3:
                    st.metric(
                        f"{forecast_months}ä¸ªæœˆåé¢„æµ‹",
                        f"${predicted_price:,.0f}"
                    )

                # ç»˜åˆ¶é¢„æµ‹å›¾
                st.subheader("ä»·æ ¼é¢„æµ‹èµ°åŠ¿")

                # å‡†å¤‡æ•°æ®
                future_dates = pd.date_range(
                    start=historical['sale_date'].iloc[-1] + timedelta(days=30),
                    periods=forecast_months,
                    freq='M'
                )

                fig = go.Figure()

                # å†å²æ•°æ®
                fig.add_trace(go.Scatter(
                    x=historical['sale_date'],
                    y=historical['avg_price'],
                    mode='lines+markers',
                    name='å†å²ä»·æ ¼',
                    line=dict(color='blue', width=2)
                ))

                # é¢„æµ‹æ•°æ®
                fig.add_trace(go.Scatter(
                    x=future_dates,
                    y=forecast['predictions'],
                    mode='lines+markers',
                    name='é¢„æµ‹ä»·æ ¼',
                    line=dict(color='red', width=2, dash='dash')
                ))

                # ç½®ä¿¡åŒºé—´
                fig.add_trace(go.Scatter(
                    x=future_dates,
                    y=forecast['confidence_upper'],
                    mode='lines',
                    name='ä¸Šé™',
                    line=dict(width=0),
                    showlegend=False
                ))

                fig.add_trace(go.Scatter(
                    x=future_dates,
                    y=forecast['confidence_lower'],
                    mode='lines',
                    name='ç½®ä¿¡åŒºé—´',
                    fill='tonexty',
                    fillcolor='rgba(255, 0, 0, 0.2)',
                    line=dict(width=0)
                ))

                fig.update_layout(
                    title=f'{selected_suburb} æˆ¿ä»·é¢„æµ‹',
                    xaxis_title='æ—¥æœŸ',
                    yaxis_title='ä»·æ ¼ ($)',
                    hovermode='x unified'
                )

                st.plotly_chart(fig, use_container_width=True)

                # é¢„æµ‹è¯¦æƒ…è¡¨
                st.subheader("é¢„æµ‹è¯¦æƒ…")
                forecast_df = pd.DataFrame({
                    'æœˆä»½': range(1, forecast_months + 1),
                    'é¢„æµ‹æ—¥æœŸ': future_dates.strftime('%Y-%m'),
                    'é¢„æµ‹ä»·æ ¼': [f"${p:,.0f}" for p in forecast['predictions']],
                    'ä¸Šé™': [f"${p:,.0f}" for p in forecast['confidence_upper']],
                    'ä¸‹é™': [f"${p:,.0f}" for p in forecast['confidence_lower']]
                })
                st.dataframe(forecast_df, use_container_width=True)

    # ==================== é¡µé¢5: ç›‘æ§è­¦æŠ¥ ====================
    elif page == "ç›‘æ§è­¦æŠ¥":
        st.title("ğŸš¨ ç›‘æ§ä¸è­¦æŠ¥")

        tab1, tab2, tab3 = st.tabs(["å®æ—¶è­¦æŠ¥", "å†å²è®°å½•", "è®¾ç½®è§„åˆ™"])

        with tab1:
            st.subheader("ä»Šæ—¥è­¦æŠ¥")

            alerts = pd.read_sql(
                "SELECT * FROM alerts WHERE DATE(created_at) = DATE('now') ORDER BY created_at DESC",
                db.conn
            )

            if alerts.empty:
                st.info("ä»Šæ—¥æš‚æ— è­¦æŠ¥")
            else:
                for _, alert in alerts.iterrows():
                    severity_colors = {
                        'HIGH': 'ğŸ”´',
                        'MEDIUM': 'ğŸŸ ',
                        'LOW': 'ğŸŸ¡',
                        'INFO': 'ğŸ”µ'
                    }

                    with st.expander(
                            f"{severity_colors[alert['severity']]} {alert['suburb']} - {alert['alert_type']}",
                            expanded=True
                    ):
                        st.write(f"**æ¶ˆæ¯**: {alert['message']}")
                        st.write(f"**æ—¶é—´**: {alert['created_at']}")
                        st.write(f"**ä¸¥é‡ç¨‹åº¦**: {alert['severity']}")

        with tab2:
            st.subheader("å†å²è­¦æŠ¥è®°å½•")

            days = st.slider("æŸ¥çœ‹æœ€è¿‘å‡ å¤©", 1, 30, 7)

            historical_alerts = pd.read_sql(f'''
                SELECT * FROM alerts 
                WHERE created_at >= datetime('now', '-{days} days')
                ORDER BY created_at DESC
            ''', db.conn)

            if not historical_alerts.empty:
                st.dataframe(historical_alerts, use_container_width=True)

                # è­¦æŠ¥ç»Ÿè®¡
                col1, col2 = st.columns(2)

                with col1:
                    severity_dist = historical_alerts['severity'].value_counts()
                    fig = px.pie(values=severity_dist.values,
                                 names=severity_dist.index,
                                 title='è­¦æŠ¥ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ')
                    st.plotly_chart(fig)

                with col2:
                    type_dist = historical_alerts['alert_type'].value_counts()
                    fig = px.bar(x=type_dist.index, y=type_dist.values,
                                 title='è­¦æŠ¥ç±»å‹åˆ†å¸ƒ')
                    st.plotly_chart(fig)

        with tab3:
            st.subheader("è­¦æŠ¥è§„åˆ™è®¾ç½®")

            st.write("è®¾ç½®ä»·æ ¼å˜åŠ¨è­¦æŠ¥é˜ˆå€¼ï¼š")

            col1, col2 = st.columns(2)

            with col1:
                price_change_threshold = st.slider(
                    "ä»·æ ¼å˜åŠ¨ç™¾åˆ†æ¯”",
                    0, 50, 10,
                    help="å½“ä»·æ ¼å˜åŠ¨è¶…è¿‡æ­¤ç™¾åˆ†æ¯”æ—¶è§¦å‘è­¦æŠ¥"
                )

            with col2:
                volume_change_threshold = st.slider(
                    "äº¤æ˜“é‡å˜åŠ¨ç™¾åˆ†æ¯”",
                    0, 100, 30,
                    help="å½“äº¤æ˜“é‡å˜åŠ¨è¶…è¿‡æ­¤ç™¾åˆ†æ¯”æ—¶è§¦å‘è­¦æŠ¥"
                )

            st.write("ç›‘æ§åŒºåŸŸï¼š")
            monitored_suburbs = st.multiselect(
                "é€‰æ‹©è¦ç›‘æ§çš„åŒºåŸŸ",
                ['Burwood', 'Strathfield', 'Croydon', 'Ashfield',
                 'Homebush', 'Concord', 'Rhodes'],
                default=['Burwood', 'Strathfield']
            )

            if st.button("ä¿å­˜è®¾ç½®"):
                st.success("è®¾ç½®å·²ä¿å­˜ï¼")

    # ==================== é¡µé¢6: APIè®¾ç½® ====================
    elif page == "APIè®¾ç½®":
        st.title("âš™ï¸ APIé…ç½®")

        st.info("é…ç½®å„æ•°æ®æºçš„APIå¯†é’¥ä»¥è·å–å®æ—¶æ•°æ®")

        with st.form("api_settings"):
            st.subheader("Domain API")
            domain_key = st.text_input(
                "API Key",
                type="password",
                help="åœ¨ https://developer.domain.com.au è·å–"
            )

            st.subheader("CoreLogic API")
            corelogic_key = st.text_input(
                "API Key",
                type="password",
                help="è”ç³»CoreLogicé”€å”®è·å–"
            )

            st.subheader("é€šçŸ¥è®¾ç½®")
            email = st.text_input("é‚®ç®±åœ°å€", help="æ¥æ”¶æ¯æ—¥æŠ¥å‘Š")

            submitted = st.form_submit_button("ä¿å­˜é…ç½®")

            if submitted:
                # ä¿å­˜åˆ°é…ç½®æ–‡ä»¶
                config = {
                    'domain_api_key': domain_key,
                    'corelogic_api_key': corelogic_key,
                    'email': email
                }

                with open('config.json', 'w') as f:
                    json.dump(config, f)

                st.success("é…ç½®å·²ä¿å­˜ï¼")

        st.divider()

        st.subheader("æµ‹è¯•APIè¿æ¥")

        if st.button("æµ‹è¯•Domain API"):
            with st.spinner("æµ‹è¯•ä¸­..."):
                try:
                    test_data = fetcher.fetch_domain_listings('Burwood')
                    if not test_data.empty:
                        st.success("âœ… Domain APIè¿æ¥æˆåŠŸ")
                        st.dataframe(test_data.head())
                    else:
                        st.warning("âš ï¸ APIè¿”å›æ•°æ®ä¸ºç©º")
                except Exception as e:
                    st.error(f"âŒ è¿æ¥å¤±è´¥: {e}")


# ==================== ä¸»ç¨‹åºå…¥å£ ====================

def main():
    """ä¸»ç¨‹åºå…¥å£"""
    import sys

    if len(sys.argv) > 1:
        mode = sys.argv[1]

        if mode == 'web':
            # å¯åŠ¨Webç•Œé¢
            print("æ­£åœ¨å¯åŠ¨Webç•Œé¢...")
            print("è¯·åœ¨æµè§ˆå™¨è®¿é—®: http://localhost:8501")
            create_streamlit_app()

        elif mode == 'monitor':
            # å¯åŠ¨è‡ªåŠ¨ç›‘æ§
            suburbs = ['Burwood', 'Strathfield', 'Croydon', 'Ashfield', 'Homebush']
            monitor = AutomatedMonitor(suburbs)

            print("=" * 60)
            print("è‡ªåŠ¨ç›‘æ§ç³»ç»Ÿå·²å¯åŠ¨")
            print("=" * 60)
            print(f"ç›‘æ§åŒºåŸŸ: {', '.join(suburbs)}")
            print("\næŒ‰ Ctrl+C åœæ­¢ç›‘æ§")

            try:
                monitor.schedule_tasks()
            except KeyboardInterrupt:
                print("\nç›‘æ§å·²åœæ­¢")
                monitor.db.close()

        elif mode == 'analyze':
            # å•æ¬¡åˆ†æ
            from property_analyzer import AustraliaPropertyAnalyzer

            analyzer = AustraliaPropertyAnalyzer()
            property_data = analyzer.build_complete_dataset()
            feature_data = analyzer.feature_engineering()
            model = analyzer.train_valuation_model()
            valuation_data = analyzer.analyze_property_valuation()
            analyzer.visualize_results(valuation_data)
            analyzer.export_report(valuation_data)

            print("\nâœ“ åˆ†æå®Œæˆï¼")

    else:
        print("=" * 60)
        print("æ¾³æ´²æˆ¿äº§æ•°æ®åˆ†æç³»ç»Ÿ")
        print("=" * 60)
        print("\nä½¿ç”¨æ–¹æ³•:")
        print("  python property_system.py web       # å¯åŠ¨Webç•Œé¢")
        print("  python property_system.py monitor   # å¯åŠ¨è‡ªåŠ¨ç›‘æ§")
        print("  python property_system.py analyze   # æ‰§è¡Œå•æ¬¡åˆ†æ")
        print("\nWebç•Œé¢åŠŸèƒ½:")
        print("  - æ•°æ®æ€»è§ˆä»ªè¡¨æ¿")
        print("  - åŒºåŸŸæ·±åº¦åˆ†æ")
        print("  - æ™ºèƒ½ä¼°å€¼æ¨¡å‹")
        print("  - æ—¶åºé¢„æµ‹")
        print("  - ç›‘æ§è­¦æŠ¥ç®¡ç†")
        print("  - APIé…ç½®")


if __name__ == "__main__":
    main()